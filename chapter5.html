<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="Chapter 4" content="width=device-width, initial-scale=1">
    <title>NoC: Chapter 4</title>
    <link href="css/style.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"
              onload="renderMathInElement(document.body);"></script>

  </head>
  <body>
    <div class="header">
      <h1>Chapter 5: Autonomous Agents</h1>
    </div>
    <div class="navbar">
      <a href="./chapter0.html">Chapter0</a>
      <a href="./chapter1.html">Chapter1</a>
      <a href="./chapter2.html">Chapter2</a>
      <a href="./chapter3.html">Chapter3</a>
      <a href="./chapter4.html">Chapter4</a>
      <a href="./chapter5.html">Chapter5</a>
      <a href="./chapter6.html">Chapter6</a>
      <a href="./index.html" class="right">Home</a>
    </div>
    <h1>The Agent</h1>
    <p>In this chapter were going to be looing into giving different objects within the canvas the ability to 'think'. In AI, the thinking object is refered to as an Agent.</p>
    <p>An Autonomous agent is something that makes it's own choices within it's environment. Up until now, I've had forces acting on objects, but these objects simply move because of the force. In this chapter we'll look into having the objects choose to move around, like a moth drawn to a flame, or fish evading a shark.</p>
    <h2>Three Key Components</h2>
    <h3>A Limited Ability to Perceive its environment</h3>
    <p>An agent takes in information from its surroundings, however we decide how much information it takes in. Is it omnipotent, knowing everything of the entire scene or does it have a limited knowlege, perhaps it only knows about other objects within a certain radius.</p>
    <h3>Decides an Action</h3>
    <p>We will have the actions be mainly forces. The environment may tell the agent there's a predator, and the action will be a force to evade it in the opposite direction.</p>
    <h3>An Autonomous Agent has no Leader</h3>
    <p>This is not as important in our context, but will still be implemented. However, sometimes this may be broken, for example if we are examining group behaviours.</p>
    <h2>Vehicles and Steering</h2>
    <p>Based on the work from computer scientist Craig Reynolds, we will be calling our Autonomous agent class <i>Vehicle</i>. The Vehicle class will build upon the previous classes.</p>
    <p> Vehicles have three layers:</p>
    <ol>
      <li>
        <p><b>Action Selection:</b> A vehicle has a goal and chooses actions based on this goal.</p>
      </li>
      <li>
        <p><b>Steering:</b> Once an action has been selected, a steering force is applied to the object. Reynolds devevloped a simple steering force formula: Steering force = desired velocity - current velocity.</p>
      </li>
      <li>
        <p><b>Locomotion:</b> For us, locomotion will mostly be ignored. The shape of our vehicles doesn't change. There is no stepping, flapping, or swimming animation. </p>
      </li>
    </ol>
    <p>We'll be looking at individual steering behaviours first that can be combined into more complex thinking. </p>
    <h1>The Steering Force</h1>
    <p>To calculate the steering force, make use of Raynolds simple steering algorithm. First we determine the direction of the target from the location of the vehicle: <code> let desired = p5.Vector.sub(target, this.position); </code> This creates a vector that points towards the target. We then scale the desired vector by a certain amount. Here I will be setting the magnitude as the maxSpeed value. Lastly we implement the algorith: <code>let steer = p5.Vector.sub(desired, this.velocity);</code>. The advantage of this steering algorithm is that it takes into account the current state of the agent. This allows the steering force to compensate for the velocity, adding a lifelike quality to the simulation. This is what causes the vehicle to ocassionaly miss the target, and have to loop around for a second or third pass to reach it.</p>
    <pre><code>
seek(target) {
  let desired = p5.Vector.sub(target, this.position);
  desired.setMag(this.maxSpeed)
  let steer = p5.Vector.sub(desired, this.velocity);
  steer.mult(2).limit(this.maxForce);
  this.applyForce(steer);
}
    </code></pre>

    <p>In the following canvas, I've implemented 2 agents to show the different steering styles</p>
    <ol>
      <li><b>Purple:</b> Directly takes target direction (desired) to be it's force: <code> this.applyForce(desired); </code></li>
      <li><b>White:</b> Uses the Raynolds steering algorithm described above.</li>
    </ol>
    <p>The key difference between the two is that the white object takes into account its own velocity as it steers. This can be seen in that the white agent corrects faster when it misses the target, while the purple agent's turning radius is much larger, almost orbital like.</p>
    <p>Lastly, I've drawn the steer force as a red vector for each of the vehicles. This is interesting because we can see standard (purple) agent always has its seek force pointing towards the target. This is in contrast to the Raynolds (white) agent whcih has more of a corrective line, with it's seek vector off from the target.</p>
    <p>One odd behaviour is once the white agent aligns it's path with the target, it's seek vector </p>

    <h4>A Little Agents: Raynolds VS Standard Steering</h4>
    <iframe src="./examples/05_agents/ex_05_0agent0/index.html" width=625 height=450 scrolling="no"></iframe>

    <h3>Adaptation</h3>
    <p>In the following, I've branched out on my own and tried implementing a little bit of an adaptive aspect to the simulation. Each vehicle now has a size and speed. Every time the vehicle collects the "food" it grows and its speed decreases. If the vehicle has not collected food for 10 seconds, it's size decreases, and it's speed increases. It's interesting that they all approach an average size larger than the starting size, but it's clear that once it get's too large, it has to come back down to a smaller, more agile size.</p>

    <h4>Adaptive Agents</h4>
    <iframe src="./examples/05_agents/ex_05_1adaptingAgents/index.html" width=625 height=450 scrolling="no"></iframe>
    <h3>Arrival</h3>
    <p>At this point our agent simply tries to move towards the target as fast as possible. Now let's have it slow down as it approaches the target; an arrival. To do this, we determine the distance from the vehicle to target, and if that distance is less than a preset radius (200px) from the target, we match the magnitude of the speed to the distance from the target: </p>
    <pre><code> let magnitude = map(distance, 0, 100, 0, this.maxSpeed); </code></pre>
    <h4>Arrival</h4>
    <iframe src="./examples/05_agents/ex_05_2arrival/index.html" width=625 height=450 scrolling="no"></iframe>
    <h3>Pursuit</h3>
    <p>Up until this point, the steering behaviour has been based on the targets position only. However, it makes more sense for our agent to predict where the object will be based on its position and velocity. This way the agent is guessing where the target will be in the next x number of frames.</p>
    <p>For this algorithm, we simply take the velocity of the target, and it to the target's position. Finally, we run the seek steering behaviour on this new location</p>
    <pre><code>
let target = vehicle.position.copy();
let velocity = vehicle.velocity.copy();
let steer = this.seek(target.add(velocity));
return steer;
    </code></pre>
    <p>Additionally, I've created a condition where if the agent is within a certain radius of the object, it changes it's steering behaviour from pursuit to seek, as pusue only ever point infront of the object. This behaviour isn't perfect, perhaps it could be improved by having a linear interpretation of the two positions, and as it gets closer, it favours the true position vs the predicted version</p>
    <p>Note that it doesn't predict bounces, which decreases the effectiveness of the agent.</p>
    <h4>Pursuit: Predicted Location With Condition</h4>
    <iframe src="./examples/05_agents/ex_05_3pursue/index.html" width=625 height=450 scrolling="no"></iframe>
    <h3>Adding Lerp</h3>
    <p>Adding a linear interpretation between the the predicted position: <code>pursue = target.position + target.velocity</code> and the target position: <code>targPos = target.position</code> we now get a smooth aligning of the predicted position with the object position, as the mover arrives.</p>
    <pre><code>
  let mapping = map(distance, 0, searchRadius, 0, 1, true);
  targDist.lerp(pursue, mapping);
  let steer = this.seek(targDist);
    </code></pre>
    <h4>Pursuit: Predicted Location With Lerp</h4>
    <iframe src="./examples/05_agents/ex_05_4pursueLerp/index.html" width=625 height=450 scrolling="no"></iframe>
    <h3>Flee and Evade:</h3>
    <p>Flee and Evade are the opposite steering behaviours of Seek and Pursue respectively. While Flee causes the object just to move away from where the target is, Evade moves the object away from where the target will be. </p>
    <h4>Flee</h4>
    <iframe src="./examples/05_agents/ex_05_5flee/index.html" width=625 height=450 scrolling="no"></iframe>
    <p>In the following:<br><b>Blue dot:</b> is the blue's prediction of where the red preditor will be moving to <br><b>Red dot:</b> is the Red's prediction of where the blue prey is going to move to</p>
    <h4>Evade</h4>
    <iframe src="./examples/05_agents/ex_05_6evade/index.html" width=625 height=450 scrolling="no"></iframe>
    <h2>Wandering</h2>
    <p>Suppose we want our agent to wander about the canvas randomly. Wandering is a type of random steering which has some long-term order. The steering direction in one frame is related to the steering direction in the next frame. This produces smoother random movement than simply generating a random x-y, direction.</p>
    <p>Reynolds achieves this using an interesting solution. First the vehicle predits its own future position as a fixed distance in front of it. Then a circle is drawn around this future position, and a random point along the circumference of the circle is selected. This point then moves randomly to the left or right around the circle, producing a change in steering. </p>
    <h4>Wander</h4>
    <iframe src="./examples/05_agents/ex_05_7wander/index.html" width=625 height=450 scrolling="no"></iframe>
    <h1>Flow Field Following</h1>
    <p>Flow fields can be thought of a grid canvas, where every grid has an errow pointing in a certain direction. As the vehicle moves around the canvas, whatever arrow it is above, becomes its velocity</p>
    <p>Let us create a class that describes the flow field</p>
    <pre><code>
class FlowField {P
  constructor() {
    this.resolution = 10;
    this.cols = floor(width/this.resolution);
    this.rows = floor(height/this.resolution);
    this.field = new Array(this.cols);
    for (let i = 0; i < this.cols; i++) {
      this.field[i] = new Array(this.rows);
    }
  }
}
    </code></pre>
    <h4>Flowfield Initialization Using Perlin Noise</h4>
    <iframe src="./examples/05_agents/ex_05_8flow/index.html" width=625 height=450 scrolling="no"></iframe>

    <h1>Group and Flocking Behaviours</h1>
    <p>Flocking is a group behaviour found in many creatures. Reynolds created a flocking simulation back in 1986. This will bring together many of the concepts within this chapter.</p>
    <p>Rules governing flocking:</p>
    <p><b>Separation:</b> Steer to avoid colliding with neighbors</p>
    <p><b>Alignment:</b> Steer in the same direction as neighbors</p>
    <p><b>Cohesion:</b> steer towards the center of the neighbors</p>
    <h4>Flocking, No Optimization</h4>
    <iframe src="./examples/05_agents/ex_05_9flock/index.html" width=625 height=450 scrolling="no"></iframe>
    <h1>Algorithm Effeciency</h1>
    <p>Group behaviour get's expensive very quickly. As we are checking each object with each other object, at minimum it is O(N^2)</p>
    <p>However, there are ways to have them only look at the other objects in their nearby vicinity</p>
    <h2>Spatial Subdivision</h2>
    <h3>Bin-Lattice Subdivision (Binning)</h3>
    <p>In binning, we divide the canvas into a grid of squares. For each object, we only check the other objects within the same bin.</p>
    <p>This involves creating a list of lists of lists. </p>
    <pre><code>
    let boids = [];
    let resolution = 40 //40 pixels per cell
    let cols = floor(width / resolution)
    let rows=  floor(height / resolution)
    let grid = new Array(cols);
    for (let i = 0; i < grid.length; i++){ 
      grid[i] = new Array(rows);
      for (let j = 0; j < grid.length; j++){
        grid[i][j] = []
      }
    }
    </code></pre>
    <p>Then every time we cycle through our <code>draw()</code> function, we go through all the boids, and place them in their appropriate cell</p>
    <pre><code>
    function draw() {
  // Each frame, the grid is reset to empty arrays.
  for (let i = 0; i < cols; i++) {
    for (let j = 0; j < rows; j++) {
      grid[i][j] = [];
    }
  }

  // Place each boid into the appropriate cell in the grid.
  for (let boid of flock.boids) {
    // Find the right column and row.
    let column = floor(boid.position.x / resolution);
    let row = floor(boid.position.y / resolution);
    // Constrain to the limits of the array.
    column = constrain(column, 0, cols - 1);
    row = constrain(row, 0, rows - 1);
    // Add the boid.
    grid[column][row].push(boid);
  }
    </code></pre>
    <h4>Flocking with Binning</h4>
    <iframe src="./examples/05_agents/ex_05_10binning/index.html" width=625 height=450 scrolling="no"></iframe>
    <p>Within the console log, I'm printing out the number of loops the code enters per frame. For 120 Boids:</p>
    <p><b>Standard flocking:</b> 43,000 loops</p>
    <p><b>Flocking with Binning:</b> 5,000 - 10,000 loops</p>
    <p>Clearly the binning is doing its job. However, binning does not adapt to the density of the objects. For example, in the first few frames, all the boids spawn at the same location. Thus, the algorithm is just as inefficient as standard flocking. We can improve upon this.</p>
    <h3>Quad-Trees:</h3>
    <p>Quad-trees allow us to look up in order nlog(n). We create rectangles, that, if there are a certain number of elements within the rectangle, it splits into four, and keeps track of these four child elements.</p>
    <p>Thus, when we need to lookup the elements, we can access the element's location within the canvas based on which tree element it is in. </p>
    <p>In the following, I'm showing the division of the quad tree as more and more elements are passed into it. After 4 elements are within a rectangle, it splits, leading to smaller rectangles.</p>
    <p>The Green rectangle is querying the quadtree to find which elements fall within it. If it finds a point, it highlights it in green</p>
    <h4>Quad-Tree, Click to Add Points</h4>
    <iframe src="./examples/05_agents/ex_05_11quad/index.html" width=625 height=450 scrolling="no"></iframe>
    <p>Attempting to use it in the flocking behaviour:</p>
    <h4>Quad-Tree, Click to Add Points</h4>
    <iframe src="./examples/05_agents/ex_05_12quadFlock/index.html" width=625 height=450 scrolling="no"></iframe>
  <h2>Further Optimizations</h2>
  <p>Naturally there are many more optimizations to look into. The book lists the following for futher diving into</p>
  <ul>
    <li>Use the magnitude squared</li>
    <li>Calculate sine and cosine lookup tables</li>
    <li>Don't make unnecessary p5.Vector objects</li>
  </ul>
  <p>However, we will stop our pursuit here. If I have time. I would like to recreate the Flocking simulation with the quad-tree, however it is not included in the textbook, and I'll have to look into it further. </p>
</html>

